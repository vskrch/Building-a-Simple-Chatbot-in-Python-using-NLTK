{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comparative Analysis of Classification Approaches for Heart Disease Prediction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vskrch/Building-a-Simple-Chatbot-in-Python-using-NLTK/blob/master/Comparative_Analysis_of_Classification_Approaches_for_Heart_Disease_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "gmeuaAlYX1X1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Project: Heart Diseases Prediction Model using Machine Learning algorithms\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uDgInKlgX1X5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import libraries"
      ]
    },
    {
      "metadata": {
        "id": "SODRD5IpX1X7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# data analysis, splitting and wrangling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "# machine learning\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ctr--4WVX1YB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset structure & description\n",
        "\n",
        "The dataset used in this project contains 14 variables. The independent variable that needs to be predicted, 'diagnosis', determines whether a person is healthy or suffer from heart disease. Experiments with the Cleveland database have concentrated on endeavours to distinguish disease presence (values 1, 2, 3, 4) from absence (value 0). There are several missing attribute values, distinguished with symbol '?'. The header row is missing in this dataset, so the column names have to be inserted manually.\n",
        "\n",
        "### Features information:\n",
        "\n",
        "- age - age in years\n",
        "- sex - sex(1 = male; 0 = female)\n",
        "- chest_pain - chest pain type (1 = typical angina; 2 = atypical angina; 3 = non-anginal pain; 4 = asymptomatic)\n",
        "- blood_pressure - resting blood pressure (in mm Hg on admission to the hospital)\n",
        "- serum_cholestoral - serum cholestoral in mg/dl\n",
        "- fasting_blood_sugar - fasting blood sugar > 120 mg/dl (1 = true; 0 = false)\n",
        "- electrocardiographic - resting electrocardiographic results (0 = normal; 1 = having ST-T; 2 = hypertrophy)\n",
        "- max_heart_rate - maximum heart rate achieved\n",
        "- induced_angina - exercise induced angina (1 = yes; 0 = no)\n",
        "- ST_depression - ST depression induced by exercise relative to rest\n",
        "- slope - the slope of the peak exercise ST segment (1 = upsloping; 2 = flat; 3 = downsloping)\n",
        "- no_of_vessels - number of major vessels (0-3) colored by flourosopy\n",
        "- thal - 3 = normal; 6 = fixed defect; 7 = reversable defect\n",
        "- diagnosis - the predicted attribute - diagnosis of heart disease (angiographic disease status) (Value 0 = < 50% diameter narrowing; Value 1 = > 50% diameter narrowing)\n",
        "\n",
        "### Types of features:\n",
        "\n",
        "__Categorical features__ (Has two or more categories and each value in that feature can be categorised by them): __sex, chest_pain__  \n",
        "\n",
        "\n",
        "__Ordinal features__ (Variable having relative ordering or sorting between the values): __fasting_blood_sugar, electrocardiographic, induced_angina, slope, no_of_vessels, thal, diagnosis__\n",
        "\n",
        "\n",
        "__Continuous features__ (Variable taking values between any two points or between the minimum or maximum values in the feature column): __age, blood_pressure, serum_cholestoral, max_heart_rate, ST_depression__\n"
      ]
    },
    {
      "metadata": {
        "id": "1y4FhiJZX1YC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ]
    },
    {
      "metadata": {
        "id": "ABC1SQX2X1YE",
        "colab_type": "code",
        "outputId": "bae9179c-af34-40ac-fba5-8638a5a8c4ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "cell_type": "code",
      "source": [
        "# column names in accordance with feature information\n",
        "col_names = ['age','sex','chest_pain','blood_pressure','serum_cholestoral','fasting_blood_sugar', 'electrocardiographic',\n",
        "             'max_heart_rate','induced_angina','ST_depression','slope','no_of_vessels','thal','diagnosis']\n",
        "\n",
        "# read the file\n",
        "df = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/processed.cleveland.data\", names=col_names, header=None, na_values=\"?\")\n",
        "\n",
        "print(\"Number of records: {}\\nNumber of variables: {}\".format(df.shape[0], df.shape[1]))\n",
        "\n",
        "# display the first 5 lines\n",
        "df.head()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of records: 303\n",
            "Number of variables: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>chest_pain</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>serum_cholestoral</th>\n",
              "      <th>fasting_blood_sugar</th>\n",
              "      <th>electrocardiographic</th>\n",
              "      <th>max_heart_rate</th>\n",
              "      <th>induced_angina</th>\n",
              "      <th>ST_depression</th>\n",
              "      <th>slope</th>\n",
              "      <th>no_of_vessels</th>\n",
              "      <th>thal</th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>63.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>145.0</td>\n",
              "      <td>233.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>286.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>108.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>67.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.6</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>37.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>250.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>187.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>41.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>130.0</td>\n",
              "      <td>204.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>172.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    age  sex  chest_pain  blood_pressure  serum_cholestoral  \\\n",
              "0  63.0  1.0         1.0           145.0              233.0   \n",
              "1  67.0  1.0         4.0           160.0              286.0   \n",
              "2  67.0  1.0         4.0           120.0              229.0   \n",
              "3  37.0  1.0         3.0           130.0              250.0   \n",
              "4  41.0  0.0         2.0           130.0              204.0   \n",
              "\n",
              "   fasting_blood_sugar  electrocardiographic  max_heart_rate  induced_angina  \\\n",
              "0                  1.0                   2.0           150.0             0.0   \n",
              "1                  0.0                   2.0           108.0             1.0   \n",
              "2                  0.0                   2.0           129.0             1.0   \n",
              "3                  0.0                   0.0           187.0             0.0   \n",
              "4                  0.0                   2.0           172.0             0.0   \n",
              "\n",
              "   ST_depression  slope  no_of_vessels  thal  diagnosis  \n",
              "0            2.3    3.0            0.0   6.0          0  \n",
              "1            1.5    2.0            3.0   3.0          2  \n",
              "2            2.6    2.0            2.0   7.0          1  \n",
              "3            3.5    3.0            0.0   3.0          0  \n",
              "4            1.4    1.0            0.0   3.0          0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "metadata": {
        "id": "-2n5EzdKX1YL",
        "colab_type": "code",
        "outputId": "e9bdc3e2-6697-4260-9e52-059cfe1207ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 303 entries, 0 to 302\n",
            "Data columns (total 14 columns):\n",
            "age                     303 non-null float64\n",
            "sex                     303 non-null float64\n",
            "chest_pain              303 non-null float64\n",
            "blood_pressure          303 non-null float64\n",
            "serum_cholestoral       303 non-null float64\n",
            "fasting_blood_sugar     303 non-null float64\n",
            "electrocardiographic    303 non-null float64\n",
            "max_heart_rate          303 non-null float64\n",
            "induced_angina          303 non-null float64\n",
            "ST_depression           303 non-null float64\n",
            "slope                   303 non-null float64\n",
            "no_of_vessels           299 non-null float64\n",
            "thal                    301 non-null float64\n",
            "diagnosis               303 non-null int64\n",
            "dtypes: float64(13), int64(1)\n",
            "memory usage: 33.2 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DPKOjp9uX1YR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "There are only 6 missing values in this dataset and all variables are recognized as numeric. From dataset description, we know, however, that most of features are categorical and it's necessary to distinguish them."
      ]
    },
    {
      "metadata": {
        "id": "jre5mamgX1YT",
        "colab_type": "code",
        "outputId": "395a574c-fd2b-4bcf-a68c-86541ae212f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# extract numeric columns and find categorical ones\n",
        "numeric_columns = ['serum_cholestoral', 'max_heart_rate', 'age', 'blood_pressure', 'ST_depression']\n",
        "categorical_columns = [c for c in df.columns if c not in numeric_columns]\n",
        "print(categorical_columns)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sex', 'chest_pain', 'fasting_blood_sugar', 'electrocardiographic', 'induced_angina', 'slope', 'no_of_vessels', 'thal', 'diagnosis']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HkxoIGS2X1YZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 2.Analyze features, identify patterns, and explore the data\n",
        "\n",
        "### Target value\n",
        "\n",
        "Knowing the distribution of target value is vital for choosing appropriate accuracy metrics and consequently properly assess different machine learning models."
      ]
    },
    {
      "metadata": {
        "id": "nJUQgC-5X1Ya",
        "colab_type": "code",
        "outputId": "3002a004-eb1b-4d5e-c789-6c0f4ebe3ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# count values of explained variable\n",
        "df.diagnosis.value_counts()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    164\n",
              "1     55\n",
              "2     36\n",
              "3     35\n",
              "4     13\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "NOgomA6VX1Yf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Since the values 1-4 indicate that a disease is present, it's reasonable to pull them together."
      ]
    },
    {
      "metadata": {
        "id": "GAx45PzLX1Yh",
        "colab_type": "code",
        "outputId": "af9c509a-9475-4e33-e12b-68da91acfbaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# create a boolean vector and map it with corresponding values (True=1, False=0)\n",
        "df.diagnosis = (df.diagnosis != 0).astype(int)\n",
        "df.diagnosis.value_counts()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    164\n",
              "1    139\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "metadata": {
        "id": "rIQblwD6X1Ym",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_mqdwREZX1Ys",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Numeric features\n",
        "\n",
        "There are 5 numeric columns, so let's take care of them first. \n",
        "Outliers occurrence in the dataset may be a result of wrong input and create undesired noise, thus our role is to evaluate their substance. A data point is considered as an outlier when it falls outside 3 standard deviations. "
      ]
    },
    {
      "metadata": {
        "id": "_eHve2NTX1Yt",
        "colab_type": "code",
        "outputId": "b02be04e-dff4-464f-ff00-22b09bc5620e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "# view of descriptive statistics\n",
        "df[numeric_columns].describe()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>serum_cholestoral</th>\n",
              "      <th>max_heart_rate</th>\n",
              "      <th>age</th>\n",
              "      <th>blood_pressure</th>\n",
              "      <th>ST_depression</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "      <td>303.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>246.693069</td>\n",
              "      <td>149.607261</td>\n",
              "      <td>54.438944</td>\n",
              "      <td>131.689769</td>\n",
              "      <td>1.039604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>51.776918</td>\n",
              "      <td>22.875003</td>\n",
              "      <td>9.038662</td>\n",
              "      <td>17.599748</td>\n",
              "      <td>1.161075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>126.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>94.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>211.000000</td>\n",
              "      <td>133.500000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>241.000000</td>\n",
              "      <td>153.000000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>0.800000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>275.000000</td>\n",
              "      <td>166.000000</td>\n",
              "      <td>61.000000</td>\n",
              "      <td>140.000000</td>\n",
              "      <td>1.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>564.000000</td>\n",
              "      <td>202.000000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>200.000000</td>\n",
              "      <td>6.200000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       serum_cholestoral  max_heart_rate         age  blood_pressure  \\\n",
              "count         303.000000      303.000000  303.000000      303.000000   \n",
              "mean          246.693069      149.607261   54.438944      131.689769   \n",
              "std            51.776918       22.875003    9.038662       17.599748   \n",
              "min           126.000000       71.000000   29.000000       94.000000   \n",
              "25%           211.000000      133.500000   48.000000      120.000000   \n",
              "50%           241.000000      153.000000   56.000000      130.000000   \n",
              "75%           275.000000      166.000000   61.000000      140.000000   \n",
              "max           564.000000      202.000000   77.000000      200.000000   \n",
              "\n",
              "       ST_depression  \n",
              "count     303.000000  \n",
              "mean        1.039604  \n",
              "std         1.161075  \n",
              "min         0.000000  \n",
              "25%         0.000000  \n",
              "50%         0.800000  \n",
              "75%         1.600000  \n",
              "max         6.200000  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "FOy4jc-vX1ZP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JKOsTQaX1ZV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Categorical features\n",
        "\n",
        "Let's take a closer look at categorical variables and see how they impact our target. "
      ]
    },
    {
      "metadata": {
        "id": "8zkftUutX1ZY",
        "colab_type": "code",
        "outputId": "d18c2fa4-1b37-4413-c7b8-1330a7440e50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "# count ill vs healthy people grouped by sex\n",
        "df.groupby(['sex','diagnosis'])['diagnosis'].count()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sex  diagnosis\n",
              "0.0  0             72\n",
              "     1             25\n",
              "1.0  0             92\n",
              "     1            114\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "SNWzo1LUX1Zf",
        "colab_type": "code",
        "outputId": "83894e91-fca6-4d7c-fcc5-c97955a4553c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# average number of diagnosed people grouped by number of blood vessels detected by fluoroscopy\n",
        "df[['no_of_vessels','diagnosis']].groupby('no_of_vessels').mean()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>no_of_vessels</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0.0</th>\n",
              "      <td>0.261364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>0.676923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2.0</th>\n",
              "      <td>0.815789</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3.0</th>\n",
              "      <td>0.850000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               diagnosis\n",
              "no_of_vessels           \n",
              "0.0             0.261364\n",
              "1.0             0.676923\n",
              "2.0             0.815789\n",
              "3.0             0.850000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "metadata": {
        "id": "FjeiM9XzX1Zl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ntpnJmUEX1Zz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 3.Data Preparation\n",
        "\n",
        "In order to make our dataset compatible with machine learning algorithms contained in Sci-kit Learn library, first of all, we need to handle all missing data.\n",
        "\n",
        "There are many options we could consider when replacing a missing value, for example:\n",
        "- A constant value that has meaning within the domain, such as 0, distinct from all other values\n",
        "- A value from another randomly selected record\n",
        "- A mean, median or mode value for the column\n",
        "- A value estimated by another predictive model"
      ]
    },
    {
      "metadata": {
        "id": "IUPMmgp4X1Z0",
        "colab_type": "code",
        "outputId": "b8721120-6601-4746-8398-748da6f1b957",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "cell_type": "code",
      "source": [
        "# show columns having missing values\n",
        "df.isnull().sum()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "age                     0\n",
              "sex                     0\n",
              "chest_pain              0\n",
              "blood_pressure          0\n",
              "serum_cholestoral       0\n",
              "fasting_blood_sugar     0\n",
              "electrocardiographic    0\n",
              "max_heart_rate          0\n",
              "induced_angina          0\n",
              "ST_depression           0\n",
              "slope                   0\n",
              "no_of_vessels           4\n",
              "thal                    2\n",
              "diagnosis               0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "metadata": {
        "id": "cvZcUd3OX1Z4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Both columns containing missing values are categorical. In such case, mode (most frequently occurring value in a given vector) is usually used for filling 'nans'. Let's follow this solution."
      ]
    },
    {
      "metadata": {
        "id": "jLzjlhOsX1Z5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# fill missing values with mode\n",
        "df['no_of_vessels'].fillna(df['no_of_vessels'].mode()[0], inplace=True)\n",
        "df['thal'].fillna(df['thal'].mode()[0], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GIOogthIX1Z8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Having clean data, a label can be separated from the data frame. It is also a good moment to split our data train and test sets. I will allocate 30% of the entire data to test set, which is typically considered as a standard split for this size of dataset."
      ]
    },
    {
      "metadata": {
        "id": "jb9pnS11X1Z9",
        "colab_type": "code",
        "outputId": "a0367bfb-faf3-4bdf-edad-8e1ccf6e0d05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# extract the target variable\n",
        "X, y = df.iloc[:, :-1], df.iloc[:, -1]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(303, 13)\n",
            "(303,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "huAQT8WYX1aF",
        "colab_type": "code",
        "outputId": "8f0e3276-6ccc-4aa2-a95c-5e3020d44ddc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "cell_type": "code",
      "source": [
        "# split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2606)\n",
        "print (\"train_set_x shape: \" + str(X_train.shape))\n",
        "print (\"train_set_y shape: \" + str(y_train.shape))\n",
        "print (\"test_set_x shape: \" + str(X_test.shape))\n",
        "print (\"test_set_y shape: \" + str(y_test.shape))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_set_x shape: (212, 13)\n",
            "train_set_y shape: (212,)\n",
            "test_set_x shape: (91, 13)\n",
            "test_set_y shape: (91,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nlEmfc-iX1aJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Data needs to be normalized or standardized before applying to machine learning algorithms. Standardization scales the data and gives information on how many standard deviations the data is placed from its mean value. Effectively, the mean of the data (µ) is 0 and the standard deviation (σ) is 1."
      ]
    },
    {
      "metadata": {
        "id": "nsiIopT3X1aK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# scale feature matrices\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cgkeZv7TX1aN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 4. Modelling and predicting with Machine Learning\n"
      ]
    },
    {
      "metadata": {
        "id": "EsVRFOT5X1aO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(X_train, y_train, X_test, y_test, classifier, **kwargs):\n",
        "    \n",
        "    \"\"\"\n",
        "    Fit the chosen model and print out the score.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # instantiate model\n",
        "    model = classifier(**kwargs)\n",
        "    \n",
        "    # train model\n",
        "    model.fit(X_train,y_train)\n",
        "    \n",
        "    # check accuracy and print out the results\n",
        "    fit_accuracy = model.score(X_train, y_train)\n",
        "    test_accuracy = model.score(X_test, y_test)\n",
        "    \n",
        "    print(f\"Train accuracy: {fit_accuracy:0.2%}\")\n",
        "    print(f\"Test accuracy: {test_accuracy:0.2%}\")\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bKTDE6b-X1aR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### K-Nearest Neighbours (KNN)\n",
        "\n",
        "K-Nearest Neighbors algorithm is a non-parametric method used for classification and regression. The principle behind nearest neighbour methods is to find a predefined number of training samples closest in distance to the new point and predict the label from these."
      ]
    },
    {
      "metadata": {
        "id": "MfcrwgruX1aS",
        "colab_type": "code",
        "outputId": "4efba97d-532c-4ad4-b7b5-8686629e14db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# KNN\n",
        "model = train_model(X_train, y_train, X_test, y_test, KNeighborsClassifier)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 88.21%\n",
            "Test accuracy: 86.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HqJ1wpOlX1aX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Despite its simplicity, the result is very promising. Let's see if KNN can perform even better by trying different 'n_neighbours' inputs."
      ]
    },
    {
      "metadata": {
        "id": "ODsU9mEUX1aY",
        "colab_type": "code",
        "outputId": "51b324b0-9af7-4007-e52e-0e5928bc4181",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "cell_type": "code",
      "source": [
        "# Seek optimal 'n_neighbours' parameter\n",
        "for i in range(1,10):\n",
        "    print(\"n_neigbors = \"+str(i))\n",
        "    train_model(X_train, y_train, X_test, y_test, KNeighborsClassifier, n_neighbors=i)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_neigbors = 1\n",
            "Train accuracy: 100.00%\n",
            "Test accuracy: 74.73%\n",
            "n_neigbors = 2\n",
            "Train accuracy: 87.74%\n",
            "Test accuracy: 79.12%\n",
            "n_neigbors = 3\n",
            "Train accuracy: 90.57%\n",
            "Test accuracy: 83.52%\n",
            "n_neigbors = 4\n",
            "Train accuracy: 87.74%\n",
            "Test accuracy: 84.62%\n",
            "n_neigbors = 5\n",
            "Train accuracy: 88.21%\n",
            "Test accuracy: 86.81%\n",
            "n_neigbors = 6\n",
            "Train accuracy: 85.38%\n",
            "Test accuracy: 86.81%\n",
            "n_neigbors = 7\n",
            "Train accuracy: 87.26%\n",
            "Test accuracy: 86.81%\n",
            "n_neigbors = 8\n",
            "Train accuracy: 85.38%\n",
            "Test accuracy: 85.71%\n",
            "n_neigbors = 9\n",
            "Train accuracy: 86.32%\n",
            "Test accuracy: 85.71%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9CXH1njBX1ab",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "It turns out that default value of n_neighbours (5) is optimal. "
      ]
    },
    {
      "metadata": {
        "id": "8dtpGNWFX1ac",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Decision Trees\n",
        "\n",
        "DT algorithm creates a model that predicts the value of a target variable by learning simple decision rules inferred from the data features. It is simple to understand and interpret and it's possible to visualize how important a particular feature was for our tree."
      ]
    },
    {
      "metadata": {
        "id": "gM0JHVwAX1ad",
        "colab_type": "code",
        "outputId": "1fd8e9a9-7111-4b8d-ea17-81575ae38975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Decision Tree\n",
        "model = train_model(X_train, y_train, X_test, y_test, DecisionTreeClassifier, random_state=2606)\n",
        "\n",
        "\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 100.00%\n",
            "Test accuracy: 75.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "W7OBMn9gX1ah",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "iBVn07PPX1ai",
        "colab_type": "code",
        "outputId": "30ca8be9-0824-41bc-9866-7a98e2b45c37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "cell_type": "code",
      "source": [
        "# Check optimal 'max_depth' parameter\n",
        "for i in range(1,8):\n",
        "    print(\"max_depth = \"+str(i))\n",
        "    train_model(X_train, y_train, X_test, y_test, DecisionTreeClassifier, max_depth=i, random_state=2606)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max_depth = 1\n",
            "Train accuracy: 76.89%\n",
            "Test accuracy: 74.73%\n",
            "max_depth = 2\n",
            "Train accuracy: 78.30%\n",
            "Test accuracy: 72.53%\n",
            "max_depth = 3\n",
            "Train accuracy: 87.74%\n",
            "Test accuracy: 76.92%\n",
            "max_depth = 4\n",
            "Train accuracy: 91.98%\n",
            "Test accuracy: 78.02%\n",
            "max_depth = 5\n",
            "Train accuracy: 94.81%\n",
            "Test accuracy: 78.02%\n",
            "max_depth = 6\n",
            "Train accuracy: 97.17%\n",
            "Test accuracy: 79.12%\n",
            "max_depth = 7\n",
            "Train accuracy: 97.64%\n",
            "Test accuracy: 75.82%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qNSz_d4VX1am",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With max_depth set as 6, the score went to almost 80%. By now, KNN outperforms Decision Tree."
      ]
    },
    {
      "metadata": {
        "id": "BYLgPUm0X1an",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Logistic Regression\n",
        "\n",
        "Logistic regression is a basic technique in statistical analysis that attempts to predict a data value based on prior observations. A logistic regression algorithm looks at the relationship between a dependent variable and one or more dependent variables."
      ]
    },
    {
      "metadata": {
        "id": "eJAW5kQoX1aq",
        "colab_type": "code",
        "outputId": "8a641075-1e41-4b4e-866c-149968ac1579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# Logistic Regression\n",
        "model = train_model(X_train, y_train, X_test, y_test, LogisticRegression)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 85.85%\n",
            "Test accuracy: 85.71%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "FBRTN3DFX1av",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Negligible difference between train and test score tells us as that model performs at the optimal level. Although the result itself is slightly lower than KNN, yet is still satisfactory. "
      ]
    },
    {
      "metadata": {
        "id": "1S9-QXx4X1ax",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Gaussian Naive Bayes\n",
        "\n",
        "In machine learning, naive Bayes classifiers are a family of simple probabilistic classifiers based on applying Bayes' theorem with strong (naive) independence assumptions between the features."
      ]
    },
    {
      "metadata": {
        "id": "2vmDatJVX1az",
        "colab_type": "code",
        "outputId": "f47b2c54-15f6-484e-ed85-bae1a235b1aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Gaussian Naive Bayes\n",
        "model = train_model(X_train, y_train, X_test, y_test, GaussianNB)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 85.38%\n",
            "Test accuracy: 86.81%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "k2ZrPaX_X1a5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This model produced the same result as leading KNN algorithm. While it slightly underfits the data, this model doesn't offer any hyperparameters for tuning and improve overall performance."
      ]
    },
    {
      "metadata": {
        "id": "tqcIwuvyX1a7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Support Vector Machines\n",
        "\n",
        "Support Vector Machines are perhaps one of the most popular machine learning algorithms. They are the go-to method for a high-performing algorithm with a little tuning. At first, let's try it on default settings."
      ]
    },
    {
      "metadata": {
        "id": "5oBJIoOdX1a8",
        "colab_type": "code",
        "outputId": "4fef2706-4cd5-4db2-d354-687d1a5fc949",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Support Vector Machines\n",
        "model = train_model(X_train, y_train, X_test, y_test, SVC)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 92.92%\n",
            "Test accuracy: 82.42%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XMVpJcaKX1bB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The above numbers are not remarkable by any means. I will adjust two parameters, \"C\", and 'kernel' to take full advantage of SVM power."
      ]
    },
    {
      "metadata": {
        "id": "mol1tZDnX1bC",
        "colab_type": "code",
        "outputId": "f55a9f2b-e273-4b90-c0fc-ee0877db89bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# tuned SVM\n",
        "model = train_model(X_train, y_train, X_test, y_test, SVC, C=0.05, kernel='linear')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 84.91%\n",
            "Test accuracy: 87.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Mz7KZRMnX1bF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "With impressive accuracy of almost 88%, Support Vector Machines are taking the lead!"
      ]
    },
    {
      "metadata": {
        "id": "PEgHqD2UtN5Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#AdaBoost\n",
        "\n",
        "**AdaBoostClassifier**"
      ]
    },
    {
      "metadata": {
        "id": "twKMv1Hnw178",
        "colab_type": "code",
        "outputId": "d8738604-2a56-41a8-9508-627c3dad5b8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Tuned Adaboost\n",
        "model = train_model(X_train, y_train, X_test, y_test,AdaBoostClassifier)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 93.40%\n",
            "Test accuracy: 79.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ai84ePSPtJsQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Network\n",
        "**MultiLayerPerceptronClassifier**"
      ]
    },
    {
      "metadata": {
        "id": "Zqy2v8Kj2m18",
        "colab_type": "code",
        "outputId": "9097f5c2-1ee9-4a71-94fb-41e05942407d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "#MLPClassifier\n",
        "model = train_model(X_train,y_train,X_test, y_test,MLPClassifier)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 90.57%\n",
            "Test accuracy: 86.81%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "gv39YC4kX1bG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Random Forests\n",
        "\n",
        "Random forests are an ensemble learning method for classification, regression and other tasks, that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees."
      ]
    },
    {
      "metadata": {
        "id": "_MkCATXDX1bM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This result did not meet our expectations. Altering 'n_estimators' parameter will surely pull out more of this strong algorithm. "
      ]
    },
    {
      "metadata": {
        "id": "bJsamoTbX1bP",
        "colab_type": "code",
        "outputId": "2c21d1ca-5d51-4dac-cef1-aa0208dedc80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# tuned Random Forests\n",
        "model = train_model(X_train, y_train, X_test, y_test, RandomForestClassifier, n_estimators=110, random_state=2606)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy: 100.00%\n",
            "Test accuracy: 87.91%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SU03HWfcX1bV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "While it is typical for Random Forests to perfectly learn and fit into training data, the test accuracy achieved outstanding 89%!"
      ]
    },
    {
      "metadata": {
        "id": "ms4AQp4sX1bW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 5. Conclusion\n",
        "\n",
        "The goal of the project was to compare different machine learning algorithms and predict if a certain person, given various personal characteristics and symptoms, will get heart disease or not. Here are the final results."
      ]
    },
    {
      "metadata": {
        "id": "r2Aq1YOL1IWr",
        "colab_type": "code",
        "outputId": "5e754341-fafe-4723-85dc-13673a17bfb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "cell_type": "code",
      "source": [
        "# initialize an empty list\n",
        "accuracy = []\n",
        "\n",
        "# list of algorithms names\n",
        "classifiers = ['KNN', 'Decision Trees', 'Logistic Regression', 'Naive Bayes', 'SVM', 'Random Forests', 'AdaBoost', 'MLPClassifier']\n",
        "\n",
        "# list of algorithms with parameters\n",
        "models = [KNeighborsClassifier(n_neighbors=5), DecisionTreeClassifier(max_depth=6, random_state=2606), LogisticRegression(), \n",
        "        GaussianNB(), SVC(C=0.05, kernel='linear'), RandomForestClassifier(n_estimators=110, random_state=2606), AdaBoostClassifier(n_estimators=110, random_state=2606), MLPClassifier(alpha=1)]\n",
        "\n",
        "# loop through algorithms and append the score into the list\n",
        "for i in models:\n",
        "    model = i\n",
        "    model.fit(X_train, y_train)\n",
        "    score = model.score(X_test, y_test)\n",
        "    accuracy.append(score)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nUApKH7rX1bZ",
        "colab_type": "code",
        "outputId": "28a1683f-b290-4469-9c07-c2d49e17c3b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "cell_type": "code",
      "source": [
        "# create a dataframe from accuracy results\n",
        "summary = pd.DataFrame({'accuracy':accuracy}, index=classifiers)       \n",
        "summary"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>KNN</th>\n",
              "      <td>0.868132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Decision Trees</th>\n",
              "      <td>0.791209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Logistic Regression</th>\n",
              "      <td>0.857143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Naive Bayes</th>\n",
              "      <td>0.868132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVM</th>\n",
              "      <td>0.879121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Random Forests</th>\n",
              "      <td>0.879121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AdaBoost</th>\n",
              "      <td>0.714286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MLPClassifier</th>\n",
              "      <td>0.879121</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     accuracy\n",
              "KNN                  0.868132\n",
              "Decision Trees       0.791209\n",
              "Logistic Regression  0.857143\n",
              "Naive Bayes          0.868132\n",
              "SVM                  0.879121\n",
              "Random Forests       0.879121\n",
              "AdaBoost             0.714286\n",
              "MLPClassifier        0.879121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "metadata": {
        "id": "feq-KEI7X1bW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XlUnZ8wTX1be",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-__bdVLNhgPP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}